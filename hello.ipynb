{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Import required libraries\n",
    "# -----------------------------\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Configure MLflow\n",
    "# -----------------------------\n",
    "\n",
    "# End any active runs from previous executions\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set the MLflow Tracking Server URL (where the UI is running)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "#tracking URL for mlflow deployed in ec2\n",
    "#mlflow.set_tracking_uri(\"http://ec2-3-110-45-123.ap-south-1.compute.amazonaws.com:5000\")\n",
    "\n",
    "mlflow.set_tag(\"experiment_type\", \"dev\")\n",
    "mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "# Create or select an experiment in MLflow\n",
    "# All runs will be stored under this experiment name\n",
    "mlflow.set_experiment(\"15thfeb_mlflow_exp\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load and prepare the dataset\n",
    "# -----------------------------\n",
    "\n",
    "# Load the Iris dataset\n",
    "# X = input features, y = target labels\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# 80% for training and 20% for testing\n",
    "# the value of random_state can't be negative\n",
    "#In Scikit-learn, it controls the shuffling applied to the data before applying the split. We use it in train_test_split for splitting data into training and testing dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Define hyperparameter values to try\n",
    "# -----------------------------\n",
    "\n",
    "# Different values for number of trees in the forest\n",
    "n_estimators_list = [10, 20, 50, 100, 200]\n",
    "\n",
    "# Different values for maximum depth of each tree\n",
    "max_depth_list = [1, 2,3, 5, 10]\n",
    "\n",
    "# -----------------------------\n",
    "# Run multiple experiments using loops\n",
    "# -----------------------------\n",
    "\n",
    "# Loop over all combinations of n_estimators and max_depth\n",
    "# Each combination will create one MLflow run\n",
    "for n_estimators in n_estimators_list:\n",
    "    for max_depth in max_depth_list:\n",
    "\n",
    "        # Start a new MLflow run\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            # -----------------------------\n",
    "            # Create and train the model\n",
    "            # -----------------------------\n",
    "\n",
    "            # Create a Random Forest model with current hyperparameters\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            # Train the model using training data\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Evaluate the model\n",
    "            # -----------------------------\n",
    "\n",
    "            # Make predictions on the test dataset\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate accuracy of the model\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Log parameters, metrics, and model to MLflow\n",
    "            # -----------------------------\n",
    "\n",
    "            # Log the hyperparameters used in this run\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "            # Log the evaluation metric (accuracy)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "            # Log (save) the trained model as an MLflow artifact\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "            # -----------------------------\n",
    "            # Print result for this run\n",
    "            # -----------------------------\n",
    "\n",
    "            print(\n",
    "                f\"Completed run: n_estimators={n_estimators}, \"\n",
    "                f\"max_depth={max_depth}, accuracy={accuracy}\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Configure MLflow\n",
    "# -----------------------------\n",
    "EXPERIMENT_NAME = \"15thfeb_mlflow_exp\"\n",
    "MODEL_NAME = \"IrisBestModel\"\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# -----------------------------\n",
    "# Find the best run\n",
    "# -----------------------------\n",
    "exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if exp is None:\n",
    "    raise Exception(f\"âŒ Experiment '{EXPERIMENT_NAME}' not found.\")\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    order_by=[\n",
    "        \"metrics.accuracy DESC\",\n",
    "        \"attributes.start_time DESC\"\n",
    "    ],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if len(runs) == 0:\n",
    "    raise Exception(\"âŒ No runs found in this experiment. Check tracking URI or experiment name.\")\n",
    "\n",
    "best_run = runs[0]\n",
    "\n",
    "print(\"ðŸ† Best Run Selected!\")\n",
    "print(\"Run ID     :\", best_run.info.run_id)\n",
    "print(\"Run Name   :\", best_run.data.tags.get(\"mlflow.runName\"))\n",
    "print(\"Accuracy   :\", best_run.data.metrics[\"accuracy\"])\n",
    "print(\"Parameters :\", best_run.data.params)\n",
    "\n",
    "# -----------------------------\n",
    "# Load the best model --> Give me the model to use\n",
    "# -----------------------------\n",
    "best_model = mlflow.sklearn.load_model(f\"runs:/{best_run.info.run_id}/model\")\n",
    "print(\"âœ… Best model loaded:\", best_model)\n",
    "\n",
    "# -----------------------------\n",
    "# Register the best model --> Make this model an official, versioned, deployable asset\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¦ Registering the best model...\")\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=MODEL_NAME\n",
    ")\n",
    "\n",
    "print(\"âœ… Model registered!\")\n",
    "print(\"Model name   :\", result.name)\n",
    "print(\"Model version:\", result.version)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
